## maximum model size at 200 variables
#####################################################################################
forward_subset = regsubsets(x=trainfs.mat, y=as.matrix(train['medv']), nvmax = 200, method = "forward")
summary_forward_subset = summary(forward_subset)
#print results
summary_forward_subset
#######################################
#AIC and BIC using iterative procedure
#######################################
sig0=var(train$medv) #sample variance of Y
#Compute IC for the models using sigma0 estimate:
BIC0 = summary_forward_subset$rss/ntrain + log(ntrain)*sig0*((seq(1,201,1))/ntrain)
AIC0 = summary_forward_subset$rss/ntrain + 2*sig0*((seq(1,201,1))/ntrain)
#Select best models
k0bic = which.min(BIC0)
k0bic
k0aic = which.min(AIC0)
k0aic
#Obtain IC estimates with sigma 1 estimate:
BIC1 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k0bic]/(ntrain-k0bic-1))*((seq(1,201,1))/ntrain)
AIC1 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k0aic]/(ntrain-k0aic-1))*((seq(1,201,1))/ntrain)
k1bic = which.min(BIC1)
k1bic
k1aic = which.min(AIC1)
k1aic
#Iterate once more to check:
BIC2 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k1bic]/(ntrain-k1bic-1))*((seq(1,201,1))/ntrain)
AIC2 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k1aic]/(ntrain-k1aic-1))*((seq(1,201,1))/ntrain)
k2bic = which.min(BIC2)
k2bic
k2aic = which.min(AIC2)
k2aic
BIC3 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k2bic]/(ntrain-k2bic-1))*((seq(1,201,1))/ntrain)
AIC3 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k2aic]/(ntrain-k2aic-1))*((seq(1,201,1))/ntrain)
k3bic = which.min(BIC3)
k3bic
k3aic = which.min(AIC3)
k3aic
BIC4 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k3bic]/(ntrain-k3bic-1))*((seq(1,201,1))/ntrain)
AIC4 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k3aic]/(ntrain-k3aic-1))*((seq(1,201,1))/ntrain)
k4bic = which.min(BIC4)
k4bic
k4aic = which.min(AIC4)
k4aic
BIC5 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k4bic]/(ntrain-k4bic-1))*((seq(1,201,1))/ntrain)
AIC5 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k4aic]/(ntrain-k4aic-1))*((seq(1,201,1))/ntrain)
k5bic = which.min(BIC5)
k5bic
k5aic = which.min(AIC5)
k5aic
BIC6 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k5bic]/(ntrain-k5bic-1))*((seq(1,201,1))/ntrain)
AIC6 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k5aic]/(ntrain-k5aic-1))*((seq(1,201,1))/ntrain)
k6bic = which.min(BIC6)
k6bic
k6aic = which.min(AIC6)
k6aic
BIC7 = summary_forward_subset$rss/ntrain + log(ntrain)*(summary_forward_subset$rss[k6bic]/(ntrain-k6bic-1))*((seq(1,201,1))/ntrain)
AIC7 = summary_forward_subset$rss/ntrain + 2*(summary_forward_subset$rss[k6aic]/(ntrain-k6aic-1))*((seq(1,201,1))/ntrain)
k7bic = which.min(BIC7)
k7bic
k7aic = which.min(AIC7)
k7aic
#bic = 28
#aic = 188
#extract coefficients from the best model on BIC
temp.coef = coef(forward_subset, id = k7bic)
test_new.mat = model.matrix(fbfs, data = test)
MSEBIC = mean((test$medv-test_new.mat[,names(temp.coef)]%*%temp.coef)^2)
MSEBIC
temp.coef = coef(forward_subset, id = k7aic)
MSEAICL = mean((test$medv-test_new.mat[,names(temp.coef)]%*%temp.coef)^2)
MSEAICL
#####################################################################################
## Part 5
#####################################################################################
set.seed(1789424)
#function(input1, input2,...) defines an R function; note the input order matters when calling;
MSE <- function(pred, truth){ #start and end body of the function by { } - same as a loop
return(mean((truth - pred)^2)) #end function with a return(output) statement. Here we can go straight to return because the object of interest is a simple function of inputs
}
#already does not contain intercept so it's fine for Ridge regression which runs on demeaned data without one
x = trainfs.mat
y = train['medv'] #define Y
#For ridge regression, we need to choose a value for lambda. Although glmnet() defaults to an automatically selected range, we can also supply our own values as we'll do here.
grid = 10^seq(10, -2, length = 100)#an example of a grid that starts denser and becomes sparser as lambda grows - taken from ISLR lab in chapter 6
#you can of course define any grid that makes sense in your applications. Several grids can be tried zooming in on "promising" intervals.
#Example of fitting the ridge model
#The argument 0 <= alpha <= 1 is the elastic net mixing parameter. A value of 0 yields ridge and a value of 1 yields Lasso (1 is default). 0 < alpha <1 yields the Elastic net, which is a combination of ridge and LASSO penalties.
ridge.mod = glmnet(x, data.matrix(y), alpha = 0, lambda = grid)
#Now try 10-fold CV with a user-defined grid:
cv.out10u = cv.glmnet(x, data.matrix(y), alpha = 0, lambda=grid)
cv.out10u
#Lambda Measure     SE Nonzero
#min  932.6   52.37 11.891    1203
#1se 2848.0   61.19  8.812    1203
plot(cv.out10u) #automatic plot
plot(cv.out10u$lambda,cv.out10u$cvm, main="Ridge 10-fold CV user-defined grid", xlab="Lambda", ylab="CV MSE") #plot shown in lecture - I find this one more intuitive
#What is the RMSE associated with the value of lambda chosen by cross-validation?
x_test = testfs.mat
ridge.pred <- predict(ridge.mod, s = cv.out10u$lambda.1se, newx = x_test)
MSE(ridge.pred, data.matrix(test['medv']))
#value = 58.32706
#####################################################################################
## Part 6
#####################################################################################
#Run the LASSO. The only change is that we need to set alpha = 1 rather than 0 (alpha=1 is also the default setting).
lasso.mod <- glmnet(x, data.matrix(y), alpha = 1, lambda = grid)
plot(lasso.mod) #this allows you to plot coefficients as a function of your L1-budget (and hence lambda)
#This is may be useful to see how and where shrinkage kicks in.
set.seed(1789424) #reset seed so that the only difference in results is due to the grid choice
cv.out10l = cv.glmnet(x, data.matrix(y), alpha = 1, lambda=grid)
plot(cv.out10l)
plot(cv.out10l$lambda,cv.out10l$cvm, main="10-fold CV user-defined grid", xlab="Lambda", ylab="CV MSE")
cv.out10l
#Measure: Mean-Squared Error
#Lambda Measure    SE Nonzero
#min 0.2848   12.62 3.050      40
#1se 0.6579   15.31 3.343      20
#What is the MSE associated with the value of lambda chosen by cross-validation?
#for lambda.min
lasso.pred <- predict(lasso.mod, s= cv.out10l$lambda.min, newx = x_test)
MSE(lasso.pred, data.matrix(test['medv']))
#ans: 18.92397
#for lambda.lse
lasso.pred2 <- predict(lasso.mod, s = cv.out10l$lambda.1se, newx = x_test)
MSE(lasso.pred2, data.matrix(test['medv']))
set.seed(1789424)
#CASE 1: homoscedastic and iid data
rlasso(x=x, y= as.matrix(y['medv']), post=FALSE, homoscedastic = TRUE)
rlasso(unlist(y)~x,  post=TRUE, penalty = list(homoscedastic = TRUE))
rlasso.fit = rlasso(unlist(y)~x,  post=FALSE, homoscedastic = TRUE)
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=TRUE, penalty = list(homoscedastic = TRUE))
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=FALSE,  X.dependent.lambda = TRUE)
rlasso.fit = rlasso(unlist(y)~x,  post=FALSE)
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=TRUE)
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=TRUE, penalty = list(homoscedastic = TRUE))
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=FALSE, penalty = list(homoscedastic = TRUE, X.dependent.lambda = FALSE))
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=FALSE, penalty = list(homoscedastic = TRUE, X.dependent.lambda = TRUE))
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=TRUE, penalty = list(homoscedastic = TRUE, X.dependent.lambda = TRUE))
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=FALSE,  X.dependent.lambda = TRUE)
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rlasso.fit = rlasso(unlist(y)~x,  post=TRUE, X.dependent.lambda = TRUE)
yhat.rlasso<- predict(rlasso.fit, newdata=x_test)
MSE(yhat.rlasso, data.matrix(test['medv']))
rm(list=ls())
library(forecast)
library(fpp)
library(ISLR)
library(glmnet)
library(hdm)
library("readxl")
library(psych) #install.packages("psych")
#read the file
df <- read_excel("Data.xlsx", sheet = "Data")
#assign x and y of the model
df$Date <- as.Date(df$Date, format = "%Y-%m-%d")
x = model.matrix(SP500EP ~ ., data = df)
x = x[,3:16] #remove constant and date
y = df$SP500EP
#assign the variables for test sets, training sets and validation sets
ntrain = 420 #data between 1980 to 2014
ntest = 60 #data between 2015 to 2019
xtrain = x[1 : ntrain,]
xtest = x[(ntrain + 1) : (ntrain + ntest),]
ytrain = y[1 : ntrain]
ytest = y[(ntrain + 1) : (ntrain + ntest)]
#read the file
df <- read_excel("/Users/Kaijing/documents/ec4308/Empirical-Performance-of-Equity-Premium-Prediction-on-Various-Machine-Learning/Data.xlsx", sheet = "Data")
#assign x and y of the model
df$Date <- as.Date(df$Date, format = "%Y-%m-%d")
x = model.matrix(SP500EP ~ ., data = df)
x = x[,3:16] #remove constant and date
y = df$SP500EP
#assign the variables for test sets, training sets and validation sets
ntrain = 420 #data between 1980 to 2014
ntest = 60 #data between 2015 to 2019
xtrain = x[1 : ntrain,]
xtest = x[(ntrain + 1) : (ntrain + ntest),]
ytrain = y[1 : ntrain]
ytest = y[(ntrain + 1) : (ntrain + ntest)]
View(df)
x = model.matrix(SP500EP ~ .-DATE, data = df)
x = model.matrix(SP500EP ~ .-Date, data = df)
View(x)
x = x[,2:15] #omit the intercept - Ridge regression is run on demeaned data without one
y = df$SP500EP #define Y
set.seed(12345)
train = df[xtrain,]
test = df[xtest,]
x_scaled <- scale(x)
aic <- c()
bic <- c()
lambdas_to_try <- 10^seq(-3, 5, length = 100)
#for all of the lambdas, run the model and compute AIC and BIC
for (lambda in seq(lambdas_to_try)) {
# Run model
model <- glmnet(x, y, alpha = 0, lambda = lambdas_to_try[lambda], standardize = TRUE)
# Extract coefficients and residuals (remove first row for the intercept)
betas <- as.vector((as.matrix(coef(model))[-1, ]))
resid <- y - (x_scaled %*% betas)
# Compute hat-matrix and degrees of freedom
ld <- lambdas_to_try[lambda] * diag(ncol(x_scaled))
H <- x_scaled %*% solve(t(x_scaled) %*% x_scaled + ld) %*% t(x_scaled)
#degrees of freedom is just the trace of the hat matrix
degfreedom <- tr(H)
# Compute information criteria
# assuming AIC(ridge) = nlog(e'e) + 2degfreedom(ridge)
#BIC(ridge) = nlog(e'e) + 2df(ridge)*log(n)
aic[lambda] <- nrow(x_scaled) * log(t(resid) %*% resid) + 2 * degfreedom
bic[lambda] <- nrow(x_scaled) * log(t(resid) %*% resid) + 2 * degfreedom * log(nrow(x_scaled))
}
# Plot information criteria against tried values of lambdas
plot(log(lambdas_to_try), aic, col = "orange", type = "l",
ylim = c(4000, 10000), ylab = "Information Criterion")
lines(log(lambdas_to_try), bic, col = "skyblue3")
legend("bottomright", lwd = 1, col = c("orange", "skyblue3"), legend = c("AIC", "BIC"))
# Optimal lambdas according to both criteria
lambda_aic <- lambdas_to_try[which.min(aic)]
lambda_aic
lambda_bic <- lambdas_to_try[which.min(bic)]
lambda_bic
# Fit final models, get their sum of squared residuals and mean squared error
model_aic <- glmnet(x, y, alpha = 0, lambda = lambda_aic, standardize = TRUE)
y_hat_aic <- predict(model_aic, x)
ssr_aic <- t(y - y_hat_aic) %*% (y - y_hat_aic)
mse_aic = mean((y - y_hat_aic)^2)
mse_aic
model_bic <- glmnet(x, y, alpha = 0, lambda = lambda_bic, standardize = TRUE)
y_hat_bic <- predict(model_bic, x)
ssr_bic <- t(y - y_hat_bic) %*% (y - y_hat_bic)
mse_bic = mean((y - y_hat_bic)^2)
mse_bic
x_scaled <- scale(x)
bic <- c()
lambdas_to_try <- 10^seq(-3, 0, length = 100)
for (lambda in seq(lambdas_to_try)) {
# Run model
model <- glmnet(x, y, alpha = 1, lambda = lambdas_to_try[lambda], standardize = TRUE)
# Extract coefficients and residuals (remove first row for the intercept)
betas <- as.vector((as.matrix(coef(model))[-1, ]))
resid <- y - (x_scaled %*% betas)
# Compute hat-matrix and degrees of freedom
ld <- lambdas_to_try[lambda] * diag(ncol(x_scaled))
H <- x_scaled %*% solve(t(x_scaled) %*% x_scaled + ld) %*% t(x_scaled)
#degrees of freedom is just the trace of the hat matrix
degfreedom <- tr(H)
# Compute information criteria
# assuming AIC(ridge) = nlog(e'e) + 2degfreedom(ridge)
#BIC(ridge) = nlog(e'e) + 2df(ridge)*log(n)
bic[lambda] <- nrow(x_scaled) * log(t(resid) %*% resid) + 2 * degfreedom * log(nrow(x_scaled))
}
# Optimal lambda
lambda_bic.lasso <- lambdas_to_try[which.min(bic)]
lambda_bic.lasso
rm(list = ls())
library(aTSA)
##########################################################
#read data
#########################################################
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
#drop first two col of s/n and date respectively
df <- df[,-2]
df <- subset(df, select=-c(inf_pctchg))
View(df)
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
#lassoa.mse12=lasso12a$errors[2]
lassoa.mse1
lassoa.mse14
lassoa.mse30
setwd("/Users/kaijing/Documents/EC4304/Dow-Jones")
source("func-lasso.R")
Y = data.matrix(df)
#get dependent variable we want to predict
yy = df$dji_pctchg
#test data
nprev = 2230 #approx 1/3 of data for test set size
oosy = tail(yy,nprev)
setwd("/Users/kaijing/Documents/EC4304/Dow-Jones")
source("func-lasso.R")
setwd("/Users/kaijing/Documents/EC4304/Dow-Jones")
source("func-lasso.R")
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
#lassoa.mse12=lasso12a$errors[2]
lassoa.mse1
lassoa.mse14
lassoa.mse30
View(df)
View(Y)
rm(list = ls())
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
#drop first two col of s/n and date respectively
df <- df[,-2]
#remove the inflation var that was causing issue
df <- subset(df, select=-c(inf_pctchg))
#Y is a matrix of all X and Y variables
Y = data.matrix(df)
#get dependent variable we want to predict
yy = df$dji_pctchg
#test data
nprev = 2230 #approx 1/3 of data for test set size
oosy = tail(yy,nprev)
View(Y)
rm(list = ls())
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
View(df)
df <- subset(df, select=-c(X, Date, inf_pctchg))
View(df)
Y = data.matrix(df)
yy = df$dji_pctchg
#test data
nprev = 2230 #approx 1/3 of data for test set size
oosy = tail(yy,nprev)
setwd("/Users/kaijing/Documents/EC4304/Dow-Jones")
source("func-lasso.R")
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
df[complete.cases(df), ]
without_na = df[complete.cases(df), ]
View(without_na)
new_DF <- df[rowSums(is.na(df)) > 0,]
View(new_DF)
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
#drop first two col of s/n and date respectively
df <- df[,-2]
#remove the inflation var that was causing issue
df <- subset(df, select=-c(X, Date, inf_pctchg))
#Y is a matrix of all X and Y variables
Y = data.matrix(df)
#get dependent variable we want to predict
yy = df$dji_pctchg
#test data
nprev = 2230 #approx 1/3 of data for test set size
oosy = tail(yy,nprev)
new_DF <- df[rowSums(is.na(df)) > 0,]
View(new_DF)
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
new_DF <- df[rowSums(is.na(df)) > 0,]
View(new_DF)
df[is.na(df)] <- 0
without_na = df[complete.cases(df), ]
rm(list = ls())
library(aTSA)
##########################################################
#read data
#########################################################
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
#drop first two col of s/n and date respectively
#remove the inflation var that was causing issue
df <- subset(df, select=-c(X, Date, inf_pctchg))
df[is.na(df)] <- 0
without_na = df[complete.cases(df), ]
#new_DF <- df[rowSums(is.na(df)) > 0,]
#Y is a matrix of all X and Y variables
Y = data.matrix(df)
#get dependent variable we want to predict
yy = df$dji_pctchg
#test data
nprev = 2230 #approx 1/3 of data for test set size
oosy = tail(yy,nprev)
setwd("/Users/kaijing/Documents/EC4304/Dow-Jones")
source("func-lasso.R")
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
#lassoa.mse12=lasso12a$errors[2]
lassoa.mse1
lassoa.mse14
lassoa.mse30
View(Y)
df[is.finite(rowSums(df)), ]
new_DF <- df[is.finite(rowSums(df)), ]
for (j in 1:ncol(df)) set(df, which(is.infinite(df[[j]])), j, NA)
install.packages('sets')
rm(list = ls())
setwd('/Users/kaijing/Documents/EC4304/Dow-Jones/Data')
df <- read.csv("final.csv")
#drop first two col of s/n and date respectively
#remove the inflation var that was causing issue
df <- subset(df, select=-c(X, Date, inf_pctchg))
for (j in 1:ncol(df)) set(df, which(is.infinite(df[[j]])), j, NA)
library(sets)
for (j in 1:ncol(df)) set(df, which(is.infinite(df[[j]])), j, NA)
df[is.finite(rowSums(df)), ]
new_DF <- df[is.finite(rowSums(df)), ]
is.na(df) <- do.call(cbind,lapply(df, is.infinite))
without_na = df[complete.cases(df), ]
is.na(df) <- sapply(df, is.infinite)
is.na(df)
without_na = df[complete.cases(df), ]
a1NotIna2 <- sqldf('SELECT * FROM df EXCEPT SELECT * FROM new_DF')
library(sqldf)
a1NotIna2 <- sqldf('SELECT * FROM df EXCEPT SELECT * FROM new_DF')
View(a1NotIna2)
df[is.na(df)] <- 0
new_DF <- df[rowSums(is.na(df)) > 0,]
Y = data.matrix(df)
#get dependent variable we want to predict
yy = df$dji_pctchg
#test data
nprev = 2230 #approx 1/3 of data for test set size
oosy = tail(yy,nprev)
setwd("/Users/kaijing/Documents/EC4304/Dow-Jones")
source("func-lasso.R")
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
#lassoa.mse12=lasso12a$errors[2]
lassoa.mse1
lassoa.mse14
lassoa.mse30
library(glmnet)
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
#lassoa.mse12=lasso12a$errors[2]
lassoa.mse1
lassoa.mse14
lassoa.mse30
library(HDeconometrics)
alpha=1 #set alpha=1 for LASSO
#Run forecasts for LASSO (BIC)
#The SP500R dependent variable is in the 1st position
#lag 1 week, 2 week, 30 days
lasso1a=lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
lasso14a=lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso30a=lasso.rolling.window(Y,nprev,1,30,alpha,IC="bic", "gaussian")
#lasso12a=lasso.rolling.window(Y,nprev,1,365,alpha,IC="bic", "gaussian")
lassoa.mse1=lasso1a$errors[2]
lassoa.mse14=lasso14a$errors[2]
lassoa.mse30=lasso30a$errors[2]
#lassoa.mse12=lasso12a$errors[2]
lassoa.mse1
lassoa.mse14
lassoa.mse30
lasso.rolling.window(Y,nprev,1,14,alpha,IC="bic", "gaussian")
lasso.rolling.window(Y,nprev,1,7,alpha,IC="bic", "gaussian")
